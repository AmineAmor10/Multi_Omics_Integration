{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Research_project_code_sample.ipynb","provenance":[{"file_id":"1x-noto2ASaaK1S64ufCp02towU9ciGzE","timestamp":1591894047710},{"file_id":"14xQdgRNXuz_Y-uwM46Qg_EyWwW1C1Bjl","timestamp":1590067515406}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"FUqsnp4n8qEv"},"source":["# !wget https://developer.nvidia.com/compute/cuda/9.2/Prod/local_installers/cuda-repo-ubuntu1710-9-2-local_9.2.88-1_amd64\n","# !wget https://developer.nvidia.com/compute/cuda/9.2/Prod/patches/1/cuda-repo-ubuntu1710-9-2-local-cublas-update-1_1.0-1_amd64\n","# !dpkg -i cuda-repo-ubuntu1710-9-2-local_9.2.88-1_amd64\n","# !apt-key add /var/cuda-repo-9-2-local/7fa2af80.pub\n","# !apt-get update\n","# !apt-get install cuda=9.2.88-1\n","# !dpkg -i cuda-repo-ubuntu1710-9-2-local-cublas-update-1_1.0-1_amd64\n","# !apt-get install nvidia-cuda-toolkit"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hS-XGUTnXecJ"},"source":["# !nvcc --version"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_NaNtX9UrEuD"},"source":["# !pip install torch==1.4.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html\n","# !pip install torch-scatter==latest+cu92 -f https://pytorch-geometric.com/whl/torch-1.4.0.html\n","# !pip install torch-sparse==latest+cu92 -f https://pytorch-geometric.com/whl/torch-1.4.0.html\n","# !pip install torch-cluster==latest+cu92 -f https://pytorch-geometric.com/whl/torch-1.4.0.html\n","# !pip install torch-spline-conv==latest+cu92 -f https://pytorch-geometric.com/whl/torch-1.4.0.html\n","# !pip install torch-geometric"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yrbtlmOpBpMo"},"source":["## Install suitable versions of Cuda and Torch:"]},{"cell_type":"code","metadata":{"id":"o2Q1dSqdxxXe"},"source":["!pip install torch==1.5.0+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n","!pip install torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n","!pip install torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n","!pip install torch-cluster==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n","!pip install torch-spline-conv==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n","!pip install torch-geometric"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AxZBKuW8w8M8","executionInfo":{"status":"ok","timestamp":1613734569586,"user_tz":-60,"elapsed":164817,"user":{"displayName":"Amine Amor","photoUrl":"","userId":"10619462721823590019"}},"outputId":"dc164f4d-4c9d-46a7-a8a8-bf135dc3ed3e"},"source":["!nvcc --version"],"execution_count":null,"outputs":[{"output_type":"stream","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2019 NVIDIA Corporation\n","Built on Sun_Jul_28_19:07:16_PDT_2019\n","Cuda compilation tools, release 10.1, V10.1.243\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LpFiiQeTWsEs"},"source":["## Import libraries for Geometric Deep Learning (Pytorch Geometric):"]},{"cell_type":"code","metadata":{"id":"Gd76nCN53yKG"},"source":["import numpy as np\n","import os.path as osp\n","import torch\n","import torch.nn.functional as F\n","import pandas as pd\n","import torch_geometric.nn as pyt_geom\n","from torch_geometric.nn import SplineConv\n","from torch_geometric.data import Data\n","from random import shuffle, randint\n","import networkx as nx\n","import matplotlib.pyplot as plt\n","import random \n","\n","import scipy.sparse as scipy\n","from torch_sparse import coalesce\n","from torch_geometric.utils import dense_to_sparse\n","from torch_geometric.data import DataLoader\n","from torch_geometric.data import Dataset\n","from torch_geometric.data import Batch\n","from networkx import parse_edgelist "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q5zEqw9ypgyF"},"source":["# **1) Load biomedical datasets for 5 tissues:**"]},{"cell_type":"code","metadata":{"id":"-HTnECHJ30kU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613039694644,"user_tz":-60,"elapsed":12164,"user":{"displayName":"Amine Amor","photoUrl":"","userId":"10619462721823590019"}},"outputId":"9bca8b8d-225f-4e37-cd6c-16dfbf8f4c56"},"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","\n","meth_files = ['Hom_Normal_Liver_gene_meth_profiles', 'Hom_Healthy_Lung_gene_meth_profiles', 'Hom_Normal_Pancreas_34yrs_gene_meth_profiles', 'Hom_Normal_AdrenalGland_34yrs_gene_meth_profiles', 'Hom_Healthy_Spleen_3yrs_gene_meth_profiles']\n","RNA_files = ['Liver', 'Lung', 'Pancreas', 'Adrenal_Gland', 'Spleen']\n","GGI_files = ['liver.dat', 'lung.dat', 'pancreas.dat', 'adrenal_gland.dat', 'spleen.dat']\n","\n","methylation_list = []\n","RNA_list = []\n","GGI_list = []\n","\n","for meth_name, RNA_name, GGI_name in zip(meth_files, RNA_files, GGI_files):\n","  meth_df = pd.read_csv(\"/gdrive/My Drive/All_data/methylation/\"+file_name, delimiter=\"\\t\")\n","  RNA_df = pd.read_csv(\"/gdrive/My Drive/All_data/RNA-seq/\"+RNA_name+\".v8.normalized_expression.bed\",  delimiter=\"\\t\") \n","  GGI_df = pd.read_csv(\"/gdrive/My Drive/All_data/GGI_networks/\"+GGI_name,  delimiter=\"\\t\") \n","  \n","  methylation_list.append(df)\n","  RNA_list.append(RNA_df)\n","  GGI_list.append(GGI_df)\n","\n","# Gene mapping between Ensembl ID and Entrez ID\n","gene_mapping = pd.read_csv(\"/gdrive/My Drive/R Gene-ID mapping/Gtex_mapping.csv\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kVID3nuzZO1h"},"source":["# GGI_list[0].head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OcGrJfb7ZPKD"},"source":["# RNA_list[4].head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7M5tCeBGZPf7"},"source":["# methylation_list[0].head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4PobPkAxH3_F"},"source":["# **2) Data Pre-processing:**"]},{"cell_type":"markdown","metadata":{"id":"IjOkUZrXHwiN"},"source":["## Gene ID mapping:"]},{"cell_type":"code","metadata":{"id":"2ou5J4ouMDqL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613039828568,"user_tz":-60,"elapsed":578,"user":{"displayName":"Amine Amor","photoUrl":"","userId":"10619462721823590019"}},"outputId":"d97a8f46-9dd1-4f6b-ceeb-1197cb2671e9"},"source":["def create_gene_id_map(gene_mapping):\n","\n","    gene_id_map = {} # Ensembl_gene_ID --> Entrez_ID\n","\n","    for ensembl_id, entrez_id in zip(gene_mapping['Ensembl_gene_ID'], gene_mapping['Entrez_ID']):\n","        if(not np.isnan(entrez_id)):\n","            gene_id_map[ensembl_id] = int(entrez_id)\n","    \n","    return gene_id_map\n","\n","gene_id_map = create_gene_id_map(gene_mapping)\n","list(gene_id_map.items())[:5]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('ENSG00000000003', 7105),\n"," ('ENSG00000000005', 64102),\n"," ('ENSG00000000419', 8813),\n"," ('ENSG00000000457', 57147),\n"," ('ENSG00000000460', 55732)]"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"wgGnJFgkICfB"},"source":["## DNA Methylation data processing:"]},{"cell_type":"code","metadata":{"id":"RG5tyVdcOh2Y"},"source":["# Dictionary to map each (gene_id, tissue_id) to its methylation data\n","def get_methylation_dic(methylation_list):\n","\n","    methylation_dic = {}\n","\n","    # Iterate over methylation data for each tissue in the list\n","    for tissue_index, meth_df in enumerate(methylation_list): \n","      \n","        # Renaming mehtylation data and selecting columns of interest\n","        meth_data = meth_df.copy()\n","        meth_data = meth_data.iloc[: , [1, 7, 8, 9, 10, 11, 12, 13, 14, 15]]\n","        meth_data.columns = [\"Gene\", \"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\", \"V7\", \"V8\", \"V9\"]  \n","\n","        new_gene_ids = [gene_id_map.get(meth_data['Gene'][i].strip(), None) for i in range(len(meth_data))]\n","        \n","        # The genes are now encoded with the entrez_id\n","        meth_data[\"Gene\"] = new_gene_ids\n","\n","        meth_data = meth_data.dropna()\n","\n","        # if multiple \"Ensembl ID\" genes were encoded to the same \"Entrez_ID\" gene, keep the first entry\n","        meth_data.drop_duplicates(subset =\"Gene\", keep = 'first', inplace = True)\n","        \n","        for idx, row in meth_data.iterrows():\n","            gene = int(row.values[0])\n","            vals = row.values[1:]\n","            new_vals = [0 if v==' na ' else round(float(v), 7) for v in vals]\n","            \n","            # map each (gene_id, tissue_id) to its 9D methylation vector\n","            methylation_dic[(gene, tissue_index)] = new_vals\n","            \n","\n","    return methylation_dic\n","      \n","\n","methylation_dic = get_methylation_dic(methylation_list)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"36V-6UBjIlDU"},"source":["## RNA-seq data processing:"]},{"cell_type":"code","metadata":{"id":"LN_rvBHlIi2u"},"source":["# Dictionary to map each (gene_id, tissue_id) to its RNA data\n","RNA_dic = {}\n","\n","def get_RNA_dic(RNA_list):\n","\n","    new_RNA_list = []\n","\n","    for tissue_index, tiss_df in enumerate(RNA_list):\n","        tiss_data = tiss_df.copy()\n","        tiss_data.drop(['#chr', 'start', 'end'], inplace=True, axis=1)\n","        gene_list = [v.split('.', 1)[0] for v in tiss_data.gene_id]\n","        tiss_data.gene_id = [gene_id_map.get(ensembl_gene, None) for ensembl_gene in gene_list] # genes are now encoded with the entrez_id\n","        tiss_data = tiss_data.dropna() # drop rows where genes can't be mapped \n","        tiss_data.drop_duplicates(subset =\"gene_id\", keep = 'first', inplace = True)\n","        new_RNA_list.append(tiss_data)\n","        \n","        for idx, row in tiss_data.iterrows():\n","            gene = int(row.values[0])\n","            vals = row.values[1:]\n","            \n","            # map each (gene_id, tissue_id) to its 208D RNA vector\n","            RNA_dic[(gene, tissue_index)] = vals\n","\n","    return RNA_dic, new_RNA_list\n","\n","RNA_dic, new_RNA_list = get_RNA_dic(RNA_list)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_vLUwxugYsYE"},"source":["### Rename columns for Gene-Gene-Interaction(GGI) data:"]},{"cell_type":"code","metadata":{"id":"XlTGd5B-RBu7"},"source":["def rename_GGI_columns():\n","    for index, GGI in enumerate(GGI_list):\n","        GGI['y'] = index\n","        GGI.columns = ['gene1', 'gene2', 'edge_type', 'y'] \n","\n","rename_GGI_columns()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jJsr11sZjfeR","executionInfo":{"status":"ok","timestamp":1613039885033,"user_tz":-60,"elapsed":590,"user":{"displayName":"Amine Amor","photoUrl":"","userId":"10619462721823590019"}},"outputId":"5eff3290-06c4-422b-c128-a0d9b5326e58"},"source":["print(len(list(RNA_dic.keys())))\n","print(len(list(methylation_dic.keys())))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["89794\n","114435\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RoJjczU5SgHR"},"source":["## Functions to create Pytorch Geometric Data Object"]},{"cell_type":"code","metadata":{"id":"tiis2WYWrGqC"},"source":["def get_features(unique_gene_ids, tissue_label, feat_dict):\n","    num_features = 0\n","    for key in feat_dict.keys():\n","        if key[1]==tissue_label:\n","            num_features = len(feat_dict[key])\n","            break\n","\n","    features = []\n","    for gene in list(unique_gene_ids): \n","        if ((gene, tissue_label) in feat_dict.keys()):\n","            features.append(np.array(feat_dict[(gene,tissue_label)]).reshape(-1,1))\n","        else:\n","            features.append(np.zeros(shape=(num_features,1)))\n","\n","    features = np.array(features)\n","    features = features.reshape((features.shape[0], features.shape[1]))\n","\n","    return torch.as_tensor(features, dtype=torch.float)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dhv_otI1OTv_"},"source":["# Assign new ID to gene nodes, from 0 to n\n","def update_GGI_data(GGI_df, sorted_uniq_gene_ids):\n","    new_GGI_df = GGI_df.copy()\n","    idx_idx_dic = {}\n","    for index, original_index in enumerate(sorted_uniq_gene_ids):\n","        idx_idx_dic[original_index] = index\n","    \n","    new_GGI_df['gene1'] = new_GGI_df.gene1.map(idx_idx_dic)\n","    new_GGI_df['gene2'] = new_GGI_df.gene2.map(idx_idx_dic)\n","    \n","    return new_GGI_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NN3yO7S8y_51"},"source":["GGI_data_list = []\n","\n","# For each Gene-Gene-Interaction(GGI) network\n","for ggi_df in GGI_list:\n","    ggi_df = ggi_df[ggi_df['edge_type']== 1]\n","    uniq_gene_ids = list(set(list(ggi_df.gene1) + list(ggi_df.gene2)))\n","    tissue_label = ggi_df.y.unique()[0] \n","\n","    # Get methylation node features\n","    meth_feat = get_features(uniq_gene_ids, tissue_label, methylation_dic)\n","    \n","    # Get RNA node features\n","    RNA_feat = get_features(uniq_gene_ids, tissue_label, RNA_dic)\n","\n","    # Get new GGI dataframe\n","    new_ggi_df = update_GGI_data(ggi_df, uniq_gene_ids)\n","\n","    # Get edges from GGI dataframe\n","    edge_index = torch.as_tensor(new_ggi_df[['gene1', 'gene2']].values.T, dtype=torch.long)\n","    \n","    # Get labels\n","    y = new_ggi_df.y.unique()\n","    y = np.ones(shape=(len(uniq_gene_ids), 1))*y\n","    y = torch.as_tensor(y, dtype=torch.long).squeeze()\n","\n","    # creating features filled with ones - equivalent to no features\n","    no_feat = torch.as_tensor(np.ones(shape=(len(uniq_gene_ids), 1)), dtype=torch.float)\n","\n","    # Final Data object\n","    ggi_data = Data(no_feat=no_feat, RNA_feat=RNA_feat, meth_feat=meth_feat, y=y, edge_index=edge_index)\n","    GGI_data_list.append(ggi_data)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yCWXx9Q1S-Rh"},"source":["### **Final Data Objects:** 5 tissue-specific networks"]},{"cell_type":"code","metadata":{"id":"9iMeZJY4tJ8W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613041509598,"user_tz":-60,"elapsed":612,"user":{"displayName":"Amine Amor","photoUrl":"","userId":"10619462721823590019"}},"outputId":"8385d081-28cc-461f-998a-8ee5dc21242c"},"source":["min_RNA_feat = np.min([GGI_data_list[0].RNA_feat.shape[1], GGI_data_list[1].RNA_feat.shape[1], GGI_data_list[2].RNA_feat.shape[1], GGI_data_list[3].RNA_feat.shape[1], GGI_data_list[4].RNA_feat.shape[1]])\n","\n","for data_obj in GGI_data_list:\n","    data_obj.RNA_feat = data_obj.RNA_feat[:, :min_RNA_feat]\n","\n","# Final list of Gene-Gene-Interaction(GGI) networks with RNA and methylation node features.\n","GGI_data_list"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Data(RNA_feat=[3315, 208], edge_index=[2, 81684], meth_feat=[3315, 9], no_feat=[3315, 1], y=[3315]),\n"," Data(RNA_feat=[3339, 208], edge_index=[2, 95722], meth_feat=[3339, 9], no_feat=[3339, 1], y=[3339]),\n"," Data(RNA_feat=[3169, 208], edge_index=[2, 70364], meth_feat=[3169, 9], no_feat=[3169, 1], y=[3169]),\n"," Data(RNA_feat=[2366, 208], edge_index=[2, 16741], meth_feat=[2366, 9], no_feat=[2366, 1], y=[2366]),\n"," Data(RNA_feat=[3058, 208], edge_index=[2, 65110], meth_feat=[3058, 9], no_feat=[3058, 1], y=[3058])]"]},"metadata":{"tags":[]},"execution_count":59}]},{"cell_type":"markdown","metadata":{"id":"PI5TR06Bcjp6"},"source":["The nodes indices were redefined in the range [0, num_nodes]. This enables each index in edge_index to access the corresponding feature vector in RNA_feat and meth_feat.\n","\n","This is a test to make sure the mapping from old indices to new indices is correct. In this example 285590 is the old index and 2990 is the new index. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A-rLjWIb2otU","executionInfo":{"status":"ok","timestamp":1613041512865,"user_tz":-60,"elapsed":581,"user":{"displayName":"Amine Amor","photoUrl":"","userId":"10619462721823590019"}},"outputId":"fb88bb8f-36c2-4f53-fc29-171e1c922490"},"source":["print(GGI_data_list[0].meth_feat[2990] == torch.as_tensor(methylation_dic[(285590,0)]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([True, True, True, True, True, True, True, True, True])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OI_ytR3ZnMC0","executionInfo":{"status":"ok","timestamp":1613041546863,"user_tz":-60,"elapsed":794,"user":{"displayName":"Amine Amor","photoUrl":"","userId":"10619462721823590019"}},"outputId":"3576014d-23cc-42f4-e6fe-bee65a21bbad"},"source":["def get_feature_coverage(GGI_data_list, tissue_index):\n","    data = GGI_data_list[tissue_index]\n","    n = len(data.y)\n","    RNA_counter = 0\n","    meth_counter = 0\n","\n","    for i in range(n):\n","        meth_feat = data.meth_feat[i]\n","        RNA_feat = data.RNA_feat[i]\n","\n","        if RNA_feat.float().sum() == 0:\n","            RNA_counter += 1\n","\n","        if meth_feat.float().sum() == 0:\n","            meth_counter += 1\n","\n","    RNA_node_coverage = np.round((1 - RNA_counter/n), 4)\n","    meth_node_coverage = np.round((1 - meth_counter/n), 4)\n","    \n","    return RNA_node_coverage, meth_node_coverage\n","\n","\n","for tissue_index in range(len(GGI_data_list)):\n","    RNA_node_coverage, meth_node_coverage = get_feature_coverage(GGI_data_list, tissue_index)\n","    print(\"TISSUE NETWORK \", tissue_index, \":\")\n","    print(\"RNA data covers \", RNA_node_coverage*100, \"% of the gene nodes\")\n","    print(\"Methylation data covers \", meth_node_coverage*100, \"% of the gene nodes\")\n","    print(\"\\n\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TISSUE NETWORK  0 :\n","RNA data covers  94.81 % of the gene nodes\n","Methylation data covers  99.58 % of the gene nodes\n","\n","\n","TISSUE NETWORK  1 :\n","RNA data covers  98.56 % of the gene nodes\n","Methylation data covers  99.58 % of the gene nodes\n","\n","\n","TISSUE NETWORK  2 :\n","RNA data covers  97.7 % of the gene nodes\n","Methylation data covers  99.56 % of the gene nodes\n","\n","\n","TISSUE NETWORK  3 :\n","RNA data covers  97.89 % of the gene nodes\n","Methylation data covers  99.53999999999999 % of the gene nodes\n","\n","\n","TISSUE NETWORK  4 :\n","RNA data covers  98.3 % of the gene nodes\n","Methylation data covers  99.57000000000001 % of the gene nodes\n","\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dOKU3TqxXwNV"},"source":["# **3) Link prediction with a Variational Graph Auto-Encoder (VGAE):**"]},{"cell_type":"markdown","metadata":{"id":"DfjhJbPJ4arA"},"source":["In this section, we train the VGAE to achieve link prediction after combining biological features (RNA+Methylation) in the latent space.\n","\n","1.   We train two separate GCN encoders (Graph Convolutional Neural Network). One is trained on a GGI network enriched with methylation features and the other is trained on a GGI network enriched with RNA features.\n","2.   The two encoded representations are then concatenated in the latent space and fed to the decoder of the VGAE which performs link prediction (i.e graph reconstruction).\n","\n"]},{"cell_type":"code","metadata":{"id":"NxhKYquJV2_E"},"source":["import networkx as nx\n","import torch_geometric\n","from scipy.sparse import coo_matrix, hstack, vstack\n","\n","# choosing the Gene-Gene-Interaction network\n","data = GGI_data_list[1]\n","\n","graph = nx.Graph()\n","edgeinfo = data.edge_index\n","src = edgeinfo[0].cpu().numpy()\n","dst = edgeinfo[1].cpu().numpy()\n","edgelist = zip(src,dst)\n","for i,j in edgelist:\n","  graph.add_edge(i,j) \n","\n","A = nx.adjacency_matrix(graph) # ADJACENCY MATRIX USED IN TRAINING\n","\n","non_edges = list(nx.non_edges(graph))\n","e0 = [tup[0] for tup in non_edges]\n","e1 = [tup[1] for tup in non_edges]\n","neg_edge_list = np.vstack((e0, e1))\n","neg_edge_index = torch.as_tensor(neg_edge_list, dtype=torch.long)\n","\n","w_factor = (neg_edge_index.shape[1]/edgeinfo.shape[1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aUhoW5o96nta"},"source":["## Build the Encoder, Decoder and VGAE class:"]},{"cell_type":"code","metadata":{"id":"5gaqdMxDUxGe"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn.parameter import Parameter\n","import torch_geometric.nn as pyg_nn\n","\n","\n","class GraphConvolution(nn.Module):\n","    \"\"\"Encoder which maps the network into a low-dimensional space.\"\"\"\n","\n","    def __init__(self, in_features, out_features, dropout=0., act=F.relu):\n","        super(GraphConvolution, self).__init__()\n","        self.in_features = in_features\n","        self.out_features = out_features\n","        self.dropout = dropout\n","        self.act = act\n","        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        torch.nn.init.xavier_uniform_(self.weight)\n","\n","    def forward(self, input, adj):\n","        input = F.dropout(input, self.dropout, self.training)\n","        support = torch.mm(input, self.weight)\n","        output = torch.spmm(adj, support)\n","        output = self.act(output)\n","        return output\n","\n","    def __repr__(self):\n","        return self.__class__.__name__ + ' (' \\\n","               + str(self.in_features) + ' -> ' \\\n","               + str(self.out_features) + ')'\n","\n","\n","class InnerProductDecoder(nn.Module):\n","    \"\"\"Decoder which uses inner product for link prediction.\"\"\"\n","\n","    def __init__(self, dropout, act=torch.sigmoid):\n","        super(InnerProductDecoder, self).__init__()\n","        self.dropout = dropout\n","        self.act = act\n","\n","    def forward(self, z):\n","        z = F.dropout(z, self.dropout, training=self.training)\n","        adj = self.act(torch.mm(z, z.t()))\n","        return adj\n","\n","\n","\n","\n","class GCNModelVAE(nn.Module): \n","    \"\"\"VGAE model which includes an encoder and a decoder.\"\"\"\n","\n","    def __init__(self, RNA_feat_dim, methy_feat_dim, hidden_dim1, hidden_dim2, dropout):\n","        super(GCNModelVAE, self).__init__()\n","        self.gcR = GraphConvolution(RNA_feat_dim, hidden_dim1, dropout, act=F.relu)\n","        self.gcM = GraphConvolution(methy_feat_dim, hidden_dim1, dropout, act=F.relu)\n","        self.gc2 = GraphConvolution(hidden_dim1*2, hidden_dim2, dropout, act=lambda x: x)\n","        self.gc3 = GraphConvolution(hidden_dim1*2, hidden_dim2, dropout, act=lambda x: x)\n","        self.dc = InnerProductDecoder(dropout, act=lambda x: x)\n","\n","    def encode(self, x_RNA, x_methy, adj):\n","        hidden1_RNA = self.gcR(x_RNA, adj)\n","        hidden1_methy = self.gcM(x_methy, adj)\n","        hidden1 = torch.cat((hidden1_RNA, hidden1_methy), 1)\n","        return self.gc2(hidden1, adj), self.gc3(hidden1, adj)\n","\n","    def reparameterize(self, mu, logvar):\n","        if self.training:\n","            std = torch.exp(logvar)\n","            eps = torch.randn_like(std)\n","            return eps.mul(std).add_(mu)\n","        else:\n","            return mu\n","\n","    def forward(self, x_RNA, x_methy, adj):\n","        mu, logvar = self.encode(x_RNA, x_methy, adj)\n","        z = self.reparameterize(mu, logvar)\n","        return self.dc(z), mu, logvar\n","\n","\n","\n","def loss_function(preds, labels, mu, logvar, n_nodes, norm, pos_weight):\n","    cost = norm * F.binary_cross_entropy_with_logits(preds, labels, pos_weight=pos_weight)\n","    KLD = -0.5 / n_nodes * torch.mean(torch.sum(1 + 2 * logvar - mu.pow(2) - logvar.exp().pow(2), 1))\n","    return cost + KLD"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lYVQ4hLQ8m5B"},"source":["## Define pre-processing functions:"]},{"cell_type":"code","metadata":{"id":"s0xxy4D3cxHJ"},"source":["import pickle as pkl\n","\n","import networkx as nx\n","import numpy as np\n","import scipy.sparse as sp\n","import torch\n","from sklearn.metrics import roc_auc_score, average_precision_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import f1_score\n","\n","\n","def parse_index_file(filename):\n","    index = []\n","    for line in open(filename):\n","        index.append(int(line.strip()))\n","    return index\n","\n","\n","def sparse_to_tuple(sparse_mx):\n","    if not sp.isspmatrix_coo(sparse_mx):\n","        sparse_mx = sparse_mx.tocoo()\n","    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n","    values = sparse_mx.data\n","    shape = sparse_mx.shape\n","    return coords, values, shape\n","\n","\n","def mask_test_edges(adj):\n","    # Function to build a test set and validation set, each with 10% of the positive links.\n","    # NOTE: Splits are randomized and results might slightly deviate from reported numbers in the paper.\n","\n","    # Remove diagonal elements\n","    adj = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n","    adj.eliminate_zeros()\n","\n","    adj_triu = sp.triu(adj)\n","    adj_tuple = sparse_to_tuple(adj_triu)\n","    edges = adj_tuple[0]\n","    edges_all = sparse_to_tuple(adj)[0]\n","    num_test = int(np.floor(edges.shape[0] / 10.))\n","    num_val = int(np.floor(edges.shape[0] / 10.))\n","\n","    all_edge_idx = list(range(edges.shape[0]))\n","    np.random.shuffle(all_edge_idx)\n","    val_edge_idx = all_edge_idx[:num_val]\n","    test_edge_idx = all_edge_idx[num_val:(num_val + num_test)]\n","    test_edges = edges[test_edge_idx]\n","    val_edges = edges[val_edge_idx]\n","    train_edges = np.delete(edges, np.hstack([test_edge_idx, val_edge_idx]), axis=0)\n","\n","    def ismember(a, b, tol=5):\n","        rows_close = np.all(np.round(a - b[:, None], tol) == 0, axis=-1)\n","        return np.any(rows_close)\n","\n","\n","    test_edges_false = []\n","    while len(test_edges_false) < len(test_edges):\n","        idx_i = np.random.randint(0, adj.shape[0])\n","        idx_j = np.random.randint(0, adj.shape[0])\n","        if idx_i == idx_j:\n","            continue\n","        if ismember([idx_i, idx_j], edges_all):\n","            continue\n","        if test_edges_false:\n","            if ismember([idx_j, idx_i], np.array(test_edges_false)):\n","                continue\n","            if ismember([idx_i, idx_j], np.array(test_edges_false)):\n","                continue\n","        test_edges_false.append([idx_i, idx_j])\n","\n","\n","    val_edges_false = []\n","    while len(val_edges_false) < len(val_edges):\n","        idx_i = np.random.randint(0, adj.shape[0])\n","        idx_j = np.random.randint(0, adj.shape[0])\n","        if idx_i == idx_j:\n","            continue\n","        if ismember([idx_i, idx_j], train_edges):\n","            continue\n","        if ismember([idx_j, idx_i], train_edges):\n","            continue\n","        if ismember([idx_i, idx_j], val_edges):\n","            continue\n","        if ismember([idx_j, idx_i], val_edges):\n","            continue\n","        if val_edges_false:\n","            if ismember([idx_j, idx_i], np.array(val_edges_false)):\n","                continue\n","            if ismember([idx_i, idx_j], np.array(val_edges_false)):\n","                continue\n","        val_edges_false.append([idx_i, idx_j])\n","\n","    data = np.ones(train_edges.shape[0])\n","\n","    # Re-build adj matrix\n","    adj_train = sp.csr_matrix((data, (train_edges[:, 0], train_edges[:, 1])), shape=adj.shape)\n","    adj_train = adj_train + adj_train.T\n","\n","    return adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false\n","\n","\n","def preprocess_graph(adj):\n","    adj = sp.coo_matrix(adj)\n","    adj_ = adj + sp.eye(adj.shape[0])\n","    rowsum = np.array(adj_.sum(1))\n","    degree_mat_inv_sqrt = sp.diags(np.power(rowsum, -0.5).flatten())\n","    adj_normalized = adj_.dot(degree_mat_inv_sqrt).transpose().dot(degree_mat_inv_sqrt).tocoo()\n","    return sparse_mx_to_torch_sparse_tensor(adj_normalized)\n","\n","\n","def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n","    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n","    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n","    indices = torch.from_numpy(\n","        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n","    values = torch.from_numpy(sparse_mx.data)\n","    shape = torch.Size(sparse_mx.shape)\n","    return torch.sparse.FloatTensor(indices, values, shape)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fw4rYSk19BwS"},"source":["## Get performance scores:"]},{"cell_type":"code","metadata":{"id":"B2O8Ei9G9AP-"},"source":["def get_scores(emb, adj_orig, edges_pos, edges_neg):\n","    def sigmoid(x):\n","        return 1 / (1 + np.exp(-x))\n","\n","    adj_rec = np.dot(emb, emb.T)\n","    preds = []\n","    pos = []\n","    for e in edges_pos:\n","        preds.append(sigmoid(adj_rec[e[0], e[1]]))\n","        pos.append(adj_orig[e[0], e[1]])\n","\n","    preds_neg = []\n","    neg = []\n","    for e in edges_neg:\n","        preds_neg.append(sigmoid(adj_rec[e[0], e[1]]))\n","        neg.append(adj_orig[e[0], e[1]])\n","\n","    preds_all = np.hstack([preds, preds_neg])\n","    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds))])\n","\n","    p = np.array([1 if  p>0.5 else 0 for p in preds_all]).reshape((-1,1))\n","    y = labels_all.reshape((-1,1))\n","    c = confusion_matrix(y, p, normalize='true')\n","    tn, fp, fn, tp = c.ravel()\n","    balanced_acc = (tp+tn)/2\n","    f1_sco = f1_score(y, p, average='weighted')\n","\n","    return balanced_acc, f1_sco"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RCENrsLfVzI8"},"source":["# ADD confusion matrices et precision-recall curves for evaluation\n","# Enable GPU"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fYTc7cluT_C9"},"source":["## Train the VGAE model:"]},{"cell_type":"code","metadata":{"id":"JxmMj3UtCcrU"},"source":["from __future__ import division\n","from __future__ import print_function\n","\n","import time\n","import numpy as np\n","import scipy.sparse as sp\n","import torch\n","from torch import optim\n","\n","seed = int(42)\n","hidden1 = int(32)\n","hidden2 = int(16)\n","lr = 0.01\n","dropout = np.float(0.2)\n","epochs = 1500\n","\n","\n","def gae_for():\n","    adj = A\n","    RNA_features = torch.as_tensor(data.RNA_feat, dtype=torch.float)\n","    methy_features = torch.as_tensor(data.meth_feat, dtype=torch.float)\n","\n","    n_nodes = RNA_features.shape[0]\n","    RNA_feat_dim = RNA_features.shape[1]\n","    methy_feat_dim = methy_features.shape[1]\n","\n","    # Store original adjacency matrix (without diagonal entries) for later\n","    adj_orig = adj\n","    adj_orig = adj_orig - sp.dia_matrix((adj_orig.diagonal()[np.newaxis, :], [0]), shape=adj_orig.shape)\n","    adj_orig.eliminate_zeros()\n","\n","    adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges(adj)\n","    adj = adj_train\n","\n","    # Some preprocessing\n","    adj_norm = preprocess_graph(adj)\n","    adj_label = adj_train + sp.eye(adj_train.shape[0])\n","    adj_label = torch.FloatTensor(adj_label.toarray())\n","\n","    w = np.ones(adj_label.shape)\n","    w = w*w_factor\n","    weight = torch.as_tensor(w, dtype=torch.float)\n","\n","    norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n","\n","    model = GCNModelVAE(RNA_feat_dim, methy_feat_dim, hidden1, hidden2, dropout)\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","\n","    hidden_emb = None\n","\n","    for epoch in range(epochs):\n","        t = time.time()\n","        model.train()\n","        optimizer.zero_grad()\n","        recovered, mu, logvar = model(RNA_features, methy_features, adj_norm)\n","        loss = loss_function(preds=recovered, labels=adj_label,\n","                             mu=mu, logvar=logvar, n_nodes=n_nodes,\n","                             norm=norm, pos_weight=weight)\n","        loss.backward()\n","        cur_loss = loss.item()\n","        optimizer.step()\n","\n","        hidden_emb = mu.data.numpy()\n","\n","        val_bal_acc, val_f1_score = get_scores(hidden_emb, adj_orig, val_edges, val_edges_false)\n","\n","        print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(cur_loss),\n","              \"val_bal_acc=\", \"{:.5f}\".format(val_bal_acc),\n","              \"val_f1_score=\", \"{:.5f}\".format(val_f1_score),\n","              \"time=\", \"{:.5f}\".format(time.time() - t)\n","              )\n","\n","    print(\"Optimization Finished!\")\n","\n","    test_bal_acc, test_f1_score = get_scores(hidden_emb, adj_orig, test_edges, test_edges_false)\n","    print('Test Bal_acc: ' + str(test_bal_acc))\n","    print('Test F1_score: ' + str(test_f1_score))\n","\n","\n","if __name__ == '__main__':\n","    gae_for()"],"execution_count":null,"outputs":[]}]}
